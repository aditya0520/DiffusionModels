11/08/2024 02:25:45 - INFO - __main__ - ***** Training arguments *****
11/08/2024 02:25:45 - INFO - __main__ - Namespace(config='configs/ddpm.yaml', data_dir='./data/imagenet100_128x128/train', image_size=128, batch_size=8, num_workers=8, num_classes=100, run_name='exp-0', output_dir='experiments', num_epochs=10, learning_rate=0.0001, weight_decay=0.0001, grad_clip=1.0, seed=42, mixed_precision='none', num_train_timesteps=1000, num_inference_steps=200, beta_start=0.0002, beta_end=0.02, beta_schedule='linear', variance_type='fixed_small', prediction_type='epsilon', clip_sample=True, clip_sample_range=1.0, unet_in_size=128, unet_in_ch=3, unet_ch=128, unet_ch_mult=[1, 2, 2, 2], unet_attn=[1, 2, 3], unet_num_res_blocks=2, unet_dropout=0.0, latent_ddpm=False, use_cfg=False, cfg_guidance_scale=2.0, use_ddim=False, ckpt='./checkpoint', distributed=False, world_size=1, rank=0, local_rank=0, device='cuda', total_batch_size=8, max_train_steps=130)
11/08/2024 02:25:45 - INFO - __main__ - ***** Running training *****
11/08/2024 02:25:45 - INFO - __main__ -   Num examples = 100
11/08/2024 02:25:45 - INFO - __main__ -   Num Epochs = 10
11/08/2024 02:25:45 - INFO - __main__ -   Instantaneous batch size per device = 8
11/08/2024 02:25:45 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 8
11/08/2024 02:25:45 - INFO - __main__ -   Total optimization steps per epoch 13
11/08/2024 02:25:45 - INFO - __main__ -   Total optimization steps = 130
  0% 0/130 [00:00<?, ?it/s]11/08/2024 02:25:45 - INFO - __main__ - Epoch 1/10
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
  1% 1/130 [00:02<04:43,  2.20s/it]11/08/2024 02:25:48 - INFO - __main__ - Epoch 1/10, Step 0/13, Loss 0.9961826205253601 (0.9961826205253601)
 10% 13/130 [00:11<01:21,  1.44it/s]Exception ignored in: <generator object tqdm.__iter__ at 0x7ca5216c07b0>
NOT USING CFG
CLASSES IS  None
guidance_scale is None
Traceback (most recent call last):s]
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1182, in __iter__
    yield obj
KeyboardInterrupt:
 24% 47/200 [00:12<00:39,  3.85it/s]
Traceback (most recent call last):
  File "/content/hw5_code/train.py", line 420, in <module>
    main()
  File "/content/hw5_code/train.py", line 400, in main
    gen_images = pipeline(batch_size=args.batch_size, num_inference_steps=args.num_inference_steps, generator=generator, device=device)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/content/hw5_code/pipelines/ddpm.py", line 110, in __call__
    model_output = self.unet(model_input, t, c)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/content/hw5_code/models/unet.py", line 84, in forward
    h = layer(h, temb, c)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/content/hw5_code/models/unet_modules.py", line 206, in forward
    h = self.block1(x)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 219, in forward
    input = module(input)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
KeyboardInterrupt
